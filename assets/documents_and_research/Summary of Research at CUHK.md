# Summary of Research at CUHK

**Author: Zhizheng Zhao**

---

## ðŸŽ¯ 1. Project Abstract

This project addresses a **fundamental theoretical limitation** in DiffCSP, a model for Crystal Structure Prediction (CSP). I first established, through theoretical analysis, that the model's reliance on **Periodic $E(3)$ Equivariance** is incomplete, as it fails to account for **Type III equivalence** arising from **Unit Cell Basis Transformations** ($\mathbf{M} \in GL(3, \mathbb{Z})$).

To achieve theoretical completeness, I proposed a **Niggli-Augmented Framework**. The core idea utilizes the **Niggli Reduction algorithm** ($\mathcal{N}$) as the mathematical tool to capture this missing Type III invariance. I designed a novel **Niggli Proxy Loss** that cleverly resolves the algorithmic non-differentiability by **decoupling** the Niggli step from the PyTorch gradient flow, effectively turning a theoretical hurdle into an engineering solution.

Preliminary experiments using a simplified MLP model successfully validated the technical feasibility of the Proxy Loss. However, a new practical bottleneck was discovered: the algorithm's **convergence failure** when processing the pathological lattices generated by the model during early training stages.

---

## 2. Motivation

The physical equivalence of crystal structures is defined by a complex manifold covering three core transformation classes. DiffCSP successfully models the first two:

| **Type** | **Equivalence Operation**             | **Transformation Relation**                                  | **DiffCSP Handling**                                         |
| :------- | :------------------------------------ | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **I**    | **External $\mathbf{O}(3)$ Rotation** | $\mathbf{L}' = \mathbf{Q}\mathbf{L} \quad (\mathbf{Q} \in \mathbf{O}(3))$ | **Resolved**. Handled by $\mathbf{O}(3)$-equivariant GNN.    |
| **II**   | **Internal Periodic Translation**     | $\mathbf{F}' = \mathbf{w}(\mathbf{F} + \mathbf{t}) \quad (\mathbf{t} \in \mathbb{R}^3)$ | **Resolved**. Handled by Fourier Features ($\mathbf{\psi}_{FT}$) and the Wrapped Normal Distribution. |
| **III**  | **Internal Basis Transformation**     | $\mathbf{L}' = \mathbf{L}\mathbf{M}, \mathbf{F}' = \mathbf{w}(\mathbf{M}^{-1}\mathbf{F}) \quad (\mathbf{M} \in GL(3, \mathbb{Z}))$ | **Unresolved (Core Limitation)**. DiffCSP's features lack invariance to the $\mathbf{M}$ transformation. |

DiffCSP relies on its training data having undergone strict crystallographic standardization. My analysis shows that the model is effectively learning a mapping to a single, unique standard representation, rather than learning the complete manifold of physical equivalence, thereby limiting its theoretical robustness.

---

## 3. Theoretical Framework

My core hypothesis is that a complete CSP model must integrate the handling of all symmetry groups:

- **DiffCSP ($E(3)$):** Accounts for Type I ($\mathbf{O}(3)$ rotation) and Type II (periodic translation).
- **Niggli Reduction ($\mathcal{N}$):** This is the perfect mathematical tool for Type III (basis transformation). The **Niggli reduction algorithm $\mathcal{N}$ uniquely maps all Type III equivalent lattices ($\mathbf{L}$ and $\mathbf{L}\mathbf{M}$) to the single canonical representation $\mathbf{L}_{\text{niggli}}$**.

Therefore, a complete DiffCSP model requires an $\mathbf{O}(3)$-equivariant GNN combined with a Niggli Proxy Loss to achieve theoretical closure.

---

## 4. Experiment

I conducted experiments on a simplified MLP model to validate the feasibility of the Niggli loss integration.

### 4.1 Finding 1 ðŸ’¡

**Problem:** Niggli reduction $\mathcal{N}$ is an iterative, discrete algorithm and thus **non-differentiable**. Direct loss comparison, $\mathcal{L}_{\text{loss}} = \text{MSE}(\mathcal{N}(\mathbf{L}_{\text{pred}}), \mathcal{N}(\mathbf{L}_{\text{label}}))$, breaks the PyTorch gradient flow at $\mathbf{L}_{\text{pred}}$.

**My Solution (Niggli Proxy Loss):** I designed a strategy to "pull" the canonical label representation into the predicted lattice's basis space, aligning the targets for a differentiable MSE calculation.

**Implementation Workflow:**

1.  **Capture Prediction Basis:** Obtain the Niggli transformation matrix $\mathbf{N}_{\text{pred}}$ from the prediction, $\mathbf{L}_{\text{pred}}$.
    $$(\_, \mathbf{N}_{\text{pred}}) = \text{NiggliReduce}(\mathbf{L}_{\text{pred}}.\text{detach()})$$
2.  **Canonicalize Label:** Obtain the canonical Niggli representation of the ground truth: $(\mathbf{L}_{\text{label,niggli}}, \mathbf{F}_{\text{label,niggli}})$.
3.  **Construct Proxy Target:** Use $\mathbf{M} = \mathbf{N}_{\text{pred}}^{-1}$ (the inverse transformation) to map the canonical label into the prediction's basis:
    * **Proxy Lattice:** $\mathbf{L}'_{\text{label}} = \mathbf{L}_{\text{label,niggli}} \cdot \mathbf{M}$
    * **Proxy Coordinates:** $\mathbf{F}'_{\text{label}} = \mathbf{w}(\mathbf{M}^{-1} \cdot \mathbf{F}_{\text{label,niggli}}) = \mathbf{w}(\mathbf{N}_{\text{pred}} \cdot \mathbf{F}_{\text{label,niggli}})$
4.  **Differentiable Loss Calculation:**
    $$\mathcal{L} = \text{MSE}(\mathbf{L}_{\text{pred}}, \mathbf{L}'_{\text{label}}) + \text{MSE}(\mathbf{F}_{\text{pred}}, \mathbf{F}'_{\text{label}})$$

**Conclusion:** The Proxy Loss successfully overcame the core non-differentiability challenge for Type III equivalence.

### 4.2 Finding 2 ðŸ“‰

**Problem:** Following the successful theoretical implementation, a severe practical bottleneck was encountered: the instability of the Niggli reduction algorithm.

**Pathological Lattices:** The untrained MLP outputs numerical unstable latticesâ€”highly skewed, near-singular ($\det(\mathbf{L}) \approx 0$), or non-physical matrices.

**Failure Mechanism:** Existing tools (e.g., `spglib`) are not robust to these inputs. Their internal iterative algorithms (like the Krivy-Gruber) **fail to converge** within the maximum iteration limit, resulting in an exception (`max_iter` error).

**Consequence:** The failure of $\text{NiggliReduce}(\mathbf{L}_{\text{pred}}.\text{detach()})$ prevents the computation of $\mathbf{N}_{\text{pred}}$, halting the entire loss calculation and crashing the training step.

---

## 5. Conclusion and Future Work

**Project Accomplishments:**

1.  **Theoretical Gap Identification:** Defined the missing $GL(3, \mathbb{Z})$ basis invariance in CSP models.
2.  **Solution Design:** Proposed the theoretically sound Niggli-Augmented Framework.
3.  **Engineering Validation:** Successfully implemented the "Niggli Proxy Loss," resolving the core non-differentiability hurdle.

**Project Outlook (Next Steps):**

I have successfully converted a **theoretical problem (invariance)** into an **engineering problem (algorithmic robustness)**. The immediate priority is resolving the Niggli algorithm's convergence failure in early training.